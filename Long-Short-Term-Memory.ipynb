{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./international-airline-passengers.csv', sep=';', usecols=[1], engine='python', skipfooter=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df.values\n",
    "dataset = dataset.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "datasetScaled = scaler.fit_transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetScaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test sets\n",
    "train_size = int(len(datasetScaled) * 0.67)\n",
    "test_size = len(datasetScaled) - train_size\n",
    "train, test = datasetScaled[0:train_size,:], datasetScaled[train_size:len(datasetScaled),:]\n",
    "print(len(train), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on the original dataset no scale\n",
    "X, Y = create_dataset(dataset, 2)\n",
    "print(X[0:5], Y[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the train and test datasets for modeling\n",
    "look_back = 1\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape input to be [samples, time steps, features]\n",
    "trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(1, look_back)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(trainX, trainY, epochs=100, batch_size=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "# invert predictions\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([trainY])\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform([testY])\n",
    "# calculate root mean squared error\n",
    "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift train predictions for plotting\n",
    "trainPredictPlot = np.empty_like(datasetScaled)\n",
    "trainPredictPlot[:, :] = np.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = np.empty_like(datasetScaled)\n",
    "testPredictPlot[:, :] = np.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(datasetScaled)-1, :] = testPredict\n",
    "# plot baseline and predictions\n",
    "plt.plot(scaler.inverse_transform(datasetScaled))\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()\n",
    "\n",
    "# showing the original dataset in blue, \n",
    "# the predictions for the training dataset in green, \n",
    "# and the predictions on the unseen test dataset in red."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply in VeloVformatted.sample.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./VeloVformatted.sample.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply in VeloV1001formatted.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./VeloV1001formatted.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply in just ID Station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data1.sort_values(['ID', 'time-stamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1[(data1['ID'] == 12002)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idStation = 1001\n",
    "_t = data1[(data1['ID'] == idStation)]\n",
    "_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use 'availabled-bikes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_t = _t.drop(['ID', 'time-stamp', 'hour', 'day-of-week', 'available-bike-stands'], axis=1)\n",
    "_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = _t.values\n",
    "dataset1 = dataset1.astype('float32')\n",
    "dataset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset1Scaled = scaler.fit_transform(dataset1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(dataset1Scaled) * 0.67)\n",
    "test_size = len(dataset1Scaled) - train_size\n",
    "train, test = dataset1Scaled[0:train_size,:], dataset1Scaled[train_size:len(dataset1Scaled),:]\n",
    "print(len(train), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on original dataset1\n",
    "X, Y = create_dataset(dataset1)\n",
    "print('X: ', X[0:5])\n",
    "print('Y: ', Y[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the train and test datasets for modeling\n",
    "look_back = 3\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainX.shape, testX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape input to be [samples, time steps, features]\n",
    "trainX = np.reshape(trainX, (trainX.shape[0], trainX.shape[1], 1))\n",
    "testX = np.reshape(testX, (testX.shape[0], testX.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainX.shape, testX.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(5, input_shape=(look_back, 1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(trainX, trainY, epochs=100, batch_size=500, verbose=2, validation_data=(testX, testY), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invert predictions\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([trainY])\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform([testY])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate root mean squared error\n",
    "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "figure(num=None, figsize=(20, 20), dpi=80, facecolor='w', edgecolor='k')\n",
    "# shift train predictions for plotting\n",
    "trainPredictPlot = np.empty_like(dataset1Scaled[:1000])\n",
    "trainPredictPlot[:, :] = np.nan\n",
    "trainPredictPlot[0:len(trainPredict[:1000])+look_back, :] = trainPredict[:1000]\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = np.empty_like(dataset1Scaled[:1000])\n",
    "testPredictPlot[:, :] = np.nan\n",
    "testPredictPlot[0:len(trainPredict[:1000])+look_back, :] = testPredict[:1000]\n",
    "# plot baseline and predictions\n",
    "plt.plot(scaler.inverse_transform(dataset1Scaled[:1000]))\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()\n",
    "\n",
    "# showing the original dataset in blue, \n",
    "# the predictions for the training dataset in green, \n",
    "# and the predictions on the unseen test dataset in red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testPredictPlot[len(trainPredict[:1000])+(look_back*2)+1:len(dataset1Scaled[:1000])-1, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test file .py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(train, test):\n",
    "    look_back = 5\n",
    "    batch_size = 5\n",
    "    \n",
    "    # prepare the train and test datasets for modeling\n",
    "    trainX, trainY = create_dataset(train, look_back)\n",
    "    testX, testY = create_dataset(test, look_back)\n",
    "\n",
    "    # reshape input to be [samples, time steps, features]\n",
    "    trainX = np.reshape(trainX, (trainX.shape[0], trainX.shape[1], 1))\n",
    "    testX = np.reshape(testX, (testX.shape[0], testX.shape[1], 1))\n",
    "\n",
    "    # create and fit the LSTM network\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(5, input_shape=(look_back, 1)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.fit(trainX, trainY, epochs=50, batch_size = batch_size, verbose=2)\n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    testPredict = model.predict(testX)\n",
    "    testPredict = scaler.inverse_transform(testPredict)\n",
    "    testY = scaler.inverse_transform([testY])\n",
    "    testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
    "    print('Test Score: %.2f RMSE' % (testScore))\n",
    "\n",
    "    return model\n",
    "\n",
    "def build_model2(dataset):\n",
    "    look_back = 5\n",
    "    batch_size = 5\n",
    "    \n",
    "    # prepare the train and test datasets for modeling\n",
    "    trainX, trainY = create_dataset(dataset, look_back)\n",
    "\n",
    "    # reshape input to be [samples, time steps, features]\n",
    "    trainX = np.reshape(trainX, (trainX.shape[0], trainX.shape[1], 1))\n",
    "\n",
    "    # create and fit the LSTM network\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(5, input_shape=(look_back, 1)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.fit(trainX, trainY, epochs=50, batch_size = batch_size, verbose=2)\n",
    "\n",
    "    return model\n",
    "\n",
    "def preprocessing(df, station):\n",
    "    _t = df[(df['ID'] == station)]\n",
    "    _t = _t.drop(['ID', 'time-stamp', 'hour', 'day-of-week', 'available-bike-stands'], axis=1)\n",
    "    dataset = _t.values\n",
    "    dataset = dataset.astype('float32')\n",
    "    return dataset\n",
    "\n",
    "def train_test_split(dataset):\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    datasetScaled = scaler.fit_transform(dataset)\n",
    "    train_size = int(len(datasetScaled) * 0.67)\n",
    "    test_size = len(datasetScaled) - train_size\n",
    "    train, test = datasetScaled[0:train_size,:], datasetScaled[train_size:len(datasetScaled), :]\n",
    "    return train, test\n",
    "\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "\n",
    "def main():\n",
    "    file = './VeloV1001formatted201502.csv'\n",
    "    df = pd.read_csv(file, sep=';')\n",
    "    stations = df['ID'].unique()\n",
    "    dfCopied = df.copy(deep = True)\n",
    "    dfCopied = dfCopied.sort_values(['ID', 'time-stamp'])\n",
    "\n",
    "    d = {}\n",
    "    for i, station in enumerate(stations):\n",
    "        print('STATION {}'.format(station))\n",
    "        _tdf = dfCopied.copy(deep=True)\n",
    "        dataset = preprocessing(_tdf, station)\n",
    "    \n",
    "        train, test = train_test_split(dataset)\n",
    "        model = build_model(train, test)\n",
    "        \n",
    "        #model = build_model2(dataset)\n",
    "        d = {station: model}\n",
    "    #print(d)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATION 1001\n",
      "Epoch 1/50\n",
      " - 7s - loss: 0.0524\n",
      "Epoch 2/50\n",
      " - 5s - loss: 0.0060\n",
      "Epoch 3/50\n",
      " - 5s - loss: 0.0054\n",
      "Epoch 4/50\n",
      " - 5s - loss: 0.0048\n",
      "Epoch 5/50\n",
      " - 5s - loss: 0.0041\n",
      "Epoch 6/50\n",
      " - 5s - loss: 0.0035\n",
      "Epoch 7/50\n",
      " - 5s - loss: 0.0032\n",
      "Epoch 8/50\n",
      " - 5s - loss: 0.0030\n",
      "Epoch 9/50\n",
      " - 5s - loss: 0.0030\n",
      "Epoch 10/50\n",
      " - 5s - loss: 0.0029\n",
      "Epoch 11/50\n",
      " - 5s - loss: 0.0029\n",
      "Epoch 12/50\n",
      " - 5s - loss: 0.0029\n",
      "Epoch 13/50\n",
      " - 5s - loss: 0.0029\n",
      "Epoch 14/50\n",
      " - 5s - loss: 0.0029\n",
      "Epoch 15/50\n",
      " - 5s - loss: 0.0028\n",
      "Epoch 16/50\n",
      " - 5s - loss: 0.0028\n",
      "Epoch 17/50\n",
      " - 5s - loss: 0.0028\n",
      "Epoch 18/50\n",
      " - 5s - loss: 0.0028\n",
      "Epoch 19/50\n",
      " - 5s - loss: 0.0028\n",
      "Epoch 20/50\n",
      " - 5s - loss: 0.0028\n",
      "Epoch 21/50\n",
      " - 5s - loss: 0.0028\n",
      "Epoch 22/50\n",
      " - 5s - loss: 0.0028\n",
      "Epoch 23/50\n",
      " - 5s - loss: 0.0028\n",
      "Epoch 24/50\n",
      " - 5s - loss: 0.0028\n",
      "Epoch 25/50\n",
      " - 5s - loss: 0.0028\n",
      "Epoch 26/50\n",
      " - 5s - loss: 0.0028\n",
      "Epoch 27/50\n",
      " - 5s - loss: 0.0028\n",
      "Epoch 28/50\n",
      " - 5s - loss: 0.0028\n",
      "Epoch 29/50\n",
      " - 5s - loss: 0.0028\n",
      "Epoch 30/50\n",
      " - 5s - loss: 0.0028\n",
      "Epoch 31/50\n",
      " - 5s - loss: 0.0028\n",
      "Epoch 32/50\n",
      " - 5s - loss: 0.0028\n",
      "Epoch 33/50\n",
      " - 5s - loss: 0.0028\n",
      "Epoch 34/50\n",
      " - 5s - loss: 0.0028\n",
      "Epoch 35/50\n",
      " - 5s - loss: 0.0028\n",
      "Epoch 36/50\n",
      " - 6s - loss: 0.0028\n",
      "Epoch 37/50\n",
      " - 6s - loss: 0.0028\n",
      "Epoch 38/50\n",
      " - 5s - loss: 0.0028\n",
      "Epoch 39/50\n",
      " - 5s - loss: 0.0028\n",
      "Epoch 40/50\n",
      " - 5s - loss: 0.0028\n",
      "Epoch 41/50\n",
      " - 5s - loss: 0.0028\n",
      "Epoch 42/50\n",
      " - 5s - loss: 0.0028\n",
      "Epoch 43/50\n",
      " - 5s - loss: 0.0028\n",
      "Epoch 44/50\n",
      " - 5s - loss: 0.0028\n",
      "Epoch 45/50\n",
      " - 5s - loss: 0.0028\n",
      "Epoch 46/50\n",
      " - 5s - loss: 0.0028\n",
      "Epoch 47/50\n",
      " - 5s - loss: 0.0028\n",
      "Epoch 48/50\n",
      " - 5s - loss: 0.0028\n",
      "Epoch 49/50\n",
      " - 5s - loss: 0.0028\n",
      "Epoch 50/50\n",
      " - 5s - loss: 0.0028\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "This MinMaxScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this method.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-128-99aa45ce5be1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-127-f1709aaa0976>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[1;31m#model = build_model2(dataset)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-127-f1709aaa0976>\u001b[0m in \u001b[0;36mbuild_model\u001b[1;34m(train, test)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mtestPredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mtestPredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestPredict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[0mtestY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtestY\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mtestScore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestPredict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\preprocessing\\data.py\u001b[0m in \u001b[0;36minverse_transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    397\u001b[0m             \u001b[0mInput\u001b[0m \u001b[0mdata\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mtransformed\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mIt\u001b[0m \u001b[0mcannot\u001b[0m \u001b[0mbe\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m         \"\"\"\n\u001b[1;32m--> 399\u001b[1;33m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'scale_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    400\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m         X = check_array(X, copy=self.copy, dtype=FLOAT_DTYPES,\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m    949\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    950\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mall_or_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mattributes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 951\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    952\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    953\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This MinMaxScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this method."
     ]
    }
   ],
   "source": [
    "d = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1001: <keras.engine.sequential.Sequential at 0x1fd9561b780>}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction\n",
    "model = d[1001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 8],\n",
       "        [ 8],\n",
       "        [ 9],\n",
       "        [ 8],\n",
       "        [10]]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = np.array([[8,8,9,8,10]])\n",
    "t = np.reshape(t, (t.shape[0], t.shape[1], 1))\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.0"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ceil(model.predict(t)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>time-stamp</th>\n",
       "      <th>hour</th>\n",
       "      <th>day-of-week</th>\n",
       "      <th>available-bike-stands</th>\n",
       "      <th>available-bikes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015-02-01 00:01:58+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015-02-01 00:02:51+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015-02-01 00:07:33+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015-02-01 00:08:22+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015-02-01 00:12:01+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015-02-01 00:22:05+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015-02-01 00:32:09+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015-02-01 00:37:15+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015-02-01 00:38:29+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015-02-01 00:38:48+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015-02-01 00:40:24+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015-02-01 00:41:27+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015-02-01 00:42:20+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015-02-01 00:51:30+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015-02-01 00:54:22+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015-02-01 01:04:25+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015-02-01 01:10:20+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015-02-01 01:11:39+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015-02-01 01:12:11+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015-02-01 01:13:37+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015-02-01 01:13:53+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015-02-01 01:22:33+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015-02-01 01:23:09+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015-02-01 01:26:11+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015-02-01 01:27:35+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015-02-01 01:28:40+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015-02-01 01:28:43+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015-02-01 01:31:47+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015-02-01 01:33:17+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015-02-01 01:34:35+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7909</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015-02-28 20:55:27+00:00</td>\n",
       "      <td>20</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7910</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015-02-28 21:05:31+00:00</td>\n",
       "      <td>21</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7911</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015-02-28 21:15:34+00:00</td>\n",
       "      <td>21</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7912</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015-02-28 21:25:37+00:00</td>\n",
       "      <td>21</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7913</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015-02-28 21:35:41+00:00</td>\n",
       "      <td>21</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7914</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015-02-28 21:45:45+00:00</td>\n",
       "      <td>21</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7915</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015-02-28 21:55:49+00:00</td>\n",
       "      <td>21</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7916</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015-02-28 22:05:52+00:00</td>\n",
       "      <td>22</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7917</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015-02-28 22:15:57+00:00</td>\n",
       "      <td>22</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7918</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015-02-28 22:26:00+00:00</td>\n",
       "      <td>22</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7919</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015-02-28 22:36:04+00:00</td>\n",
       "      <td>22</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7920</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015-02-28 22:46:08+00:00</td>\n",
       "      <td>22</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7921</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015-02-28 22:56:11+00:00</td>\n",
       "      <td>22</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7922</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015-02-28 23:00:33+00:00</td>\n",
       "      <td>23</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7923</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015-02-28 23:00:45+00:00</td>\n",
       "      <td>23</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7924</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015-02-28 23:10:09+00:00</td>\n",
       "      <td>23</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7925</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015-02-28 23:11:11+00:00</td>\n",
       "      <td>23</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7926</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015-02-28 23:21:14+00:00</td>\n",
       "      <td>23</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7927</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015-02-28 23:31:18+00:00</td>\n",
       "      <td>23</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7928</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015-02-28 23:33:21+00:00</td>\n",
       "      <td>23</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7929</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015-02-28 23:38:36+00:00</td>\n",
       "      <td>23</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7930</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015-02-28 23:42:11+00:00</td>\n",
       "      <td>23</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7931</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015-02-28 23:43:13+00:00</td>\n",
       "      <td>23</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7932</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015-02-28 23:43:48+00:00</td>\n",
       "      <td>23</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7933</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015-02-28 23:45:27+00:00</td>\n",
       "      <td>23</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7934</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015-02-28 23:46:09+00:00</td>\n",
       "      <td>23</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7935</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015-02-28 23:47:07+00:00</td>\n",
       "      <td>23</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7936</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015-02-28 23:50:35+00:00</td>\n",
       "      <td>23</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7937</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015-02-28 23:51:07+00:00</td>\n",
       "      <td>23</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7938</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015-02-28 23:51:48+00:00</td>\n",
       "      <td>23</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7939 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                 time-stamp  hour day-of-week  \\\n",
       "0     1001  2015-02-01 00:01:58+00:00     0      Sunday   \n",
       "1     1001  2015-02-01 00:02:51+00:00     0      Sunday   \n",
       "2     1001  2015-02-01 00:07:33+00:00     0      Sunday   \n",
       "3     1001  2015-02-01 00:08:22+00:00     0      Sunday   \n",
       "4     1001  2015-02-01 00:12:01+00:00     0      Sunday   \n",
       "5     1001  2015-02-01 00:22:05+00:00     0      Sunday   \n",
       "6     1001  2015-02-01 00:32:09+00:00     0      Sunday   \n",
       "7     1001  2015-02-01 00:37:15+00:00     0      Sunday   \n",
       "8     1001  2015-02-01 00:38:29+00:00     0      Sunday   \n",
       "9     1001  2015-02-01 00:38:48+00:00     0      Sunday   \n",
       "10    1001  2015-02-01 00:40:24+00:00     0      Sunday   \n",
       "11    1001  2015-02-01 00:41:27+00:00     0      Sunday   \n",
       "12    1001  2015-02-01 00:42:20+00:00     0      Sunday   \n",
       "13    1001  2015-02-01 00:51:30+00:00     0      Sunday   \n",
       "14    1001  2015-02-01 00:54:22+00:00     0      Sunday   \n",
       "15    1001  2015-02-01 01:04:25+00:00     1      Sunday   \n",
       "16    1001  2015-02-01 01:10:20+00:00     1      Sunday   \n",
       "17    1001  2015-02-01 01:11:39+00:00     1      Sunday   \n",
       "18    1001  2015-02-01 01:12:11+00:00     1      Sunday   \n",
       "19    1001  2015-02-01 01:13:37+00:00     1      Sunday   \n",
       "20    1001  2015-02-01 01:13:53+00:00     1      Sunday   \n",
       "21    1001  2015-02-01 01:22:33+00:00     1      Sunday   \n",
       "22    1001  2015-02-01 01:23:09+00:00     1      Sunday   \n",
       "23    1001  2015-02-01 01:26:11+00:00     1      Sunday   \n",
       "24    1001  2015-02-01 01:27:35+00:00     1      Sunday   \n",
       "25    1001  2015-02-01 01:28:40+00:00     1      Sunday   \n",
       "26    1001  2015-02-01 01:28:43+00:00     1      Sunday   \n",
       "27    1001  2015-02-01 01:31:47+00:00     1      Sunday   \n",
       "28    1001  2015-02-01 01:33:17+00:00     1      Sunday   \n",
       "29    1001  2015-02-01 01:34:35+00:00     1      Sunday   \n",
       "...    ...                        ...   ...         ...   \n",
       "7909  1001  2015-02-28 20:55:27+00:00    20    Saturday   \n",
       "7910  1001  2015-02-28 21:05:31+00:00    21    Saturday   \n",
       "7911  1001  2015-02-28 21:15:34+00:00    21    Saturday   \n",
       "7912  1001  2015-02-28 21:25:37+00:00    21    Saturday   \n",
       "7913  1001  2015-02-28 21:35:41+00:00    21    Saturday   \n",
       "7914  1001  2015-02-28 21:45:45+00:00    21    Saturday   \n",
       "7915  1001  2015-02-28 21:55:49+00:00    21    Saturday   \n",
       "7916  1001  2015-02-28 22:05:52+00:00    22    Saturday   \n",
       "7917  1001  2015-02-28 22:15:57+00:00    22    Saturday   \n",
       "7918  1001  2015-02-28 22:26:00+00:00    22    Saturday   \n",
       "7919  1001  2015-02-28 22:36:04+00:00    22    Saturday   \n",
       "7920  1001  2015-02-28 22:46:08+00:00    22    Saturday   \n",
       "7921  1001  2015-02-28 22:56:11+00:00    22    Saturday   \n",
       "7922  1001  2015-02-28 23:00:33+00:00    23    Saturday   \n",
       "7923  1001  2015-02-28 23:00:45+00:00    23    Saturday   \n",
       "7924  1001  2015-02-28 23:10:09+00:00    23    Saturday   \n",
       "7925  1001  2015-02-28 23:11:11+00:00    23    Saturday   \n",
       "7926  1001  2015-02-28 23:21:14+00:00    23    Saturday   \n",
       "7927  1001  2015-02-28 23:31:18+00:00    23    Saturday   \n",
       "7928  1001  2015-02-28 23:33:21+00:00    23    Saturday   \n",
       "7929  1001  2015-02-28 23:38:36+00:00    23    Saturday   \n",
       "7930  1001  2015-02-28 23:42:11+00:00    23    Saturday   \n",
       "7931  1001  2015-02-28 23:43:13+00:00    23    Saturday   \n",
       "7932  1001  2015-02-28 23:43:48+00:00    23    Saturday   \n",
       "7933  1001  2015-02-28 23:45:27+00:00    23    Saturday   \n",
       "7934  1001  2015-02-28 23:46:09+00:00    23    Saturday   \n",
       "7935  1001  2015-02-28 23:47:07+00:00    23    Saturday   \n",
       "7936  1001  2015-02-28 23:50:35+00:00    23    Saturday   \n",
       "7937  1001  2015-02-28 23:51:07+00:00    23    Saturday   \n",
       "7938  1001  2015-02-28 23:51:48+00:00    23    Saturday   \n",
       "\n",
       "      available-bike-stands  available-bikes  \n",
       "0                         2               14  \n",
       "1                         3               13  \n",
       "2                         3               13  \n",
       "3                         4               12  \n",
       "4                         3               13  \n",
       "5                         3               13  \n",
       "6                         3               13  \n",
       "7                         4               12  \n",
       "8                         4               12  \n",
       "9                         5               11  \n",
       "10                        6               10  \n",
       "11                        6               10  \n",
       "12                        8                8  \n",
       "13                        9                7  \n",
       "14                        8                8  \n",
       "15                        8                8  \n",
       "16                        9                7  \n",
       "17                        9                7  \n",
       "18                       10                6  \n",
       "19                        9                7  \n",
       "20                        8                8  \n",
       "21                        9                7  \n",
       "22                        8                8  \n",
       "23                        9                7  \n",
       "24                       10                6  \n",
       "25                       10                6  \n",
       "26                        9                7  \n",
       "27                        8                8  \n",
       "28                        9                7  \n",
       "29                        9                7  \n",
       "...                     ...              ...  \n",
       "7909                      0               15  \n",
       "7910                      0               15  \n",
       "7911                      0               15  \n",
       "7912                      0               15  \n",
       "7913                      0               15  \n",
       "7914                      0               15  \n",
       "7915                      0               15  \n",
       "7916                      0               15  \n",
       "7917                      0               15  \n",
       "7918                      0               15  \n",
       "7919                      0               15  \n",
       "7920                      0               15  \n",
       "7921                      0               15  \n",
       "7922                      0               15  \n",
       "7923                      0               15  \n",
       "7924                      1               14  \n",
       "7925                      0               15  \n",
       "7926                      0               15  \n",
       "7927                      0               15  \n",
       "7928                      1               14  \n",
       "7929                      0               15  \n",
       "7930                      1               14  \n",
       "7931                      1               14  \n",
       "7932                      2               13  \n",
       "7933                      3               12  \n",
       "7934                      4               11  \n",
       "7935                      6                9  \n",
       "7936                      6                9  \n",
       "7937                      3               12  \n",
       "7938                      1               14  \n",
       "\n",
       "[7939 rows x 6 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = './VeloV1001formatted201502.csv'\n",
    "df = pd.read_csv(file, sep=';')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16, 13,  4,  7, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
       "       13, 13, 13, 13, 13, 13, 13])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = [16,13,4,7,13]\n",
    "start = np.array([table])\n",
    "for i in range(19):\n",
    "    t = start\n",
    "    t = np.reshape(start, (start.shape[0], start.shape[1], 1))\n",
    "    yhat = round(model.predict(t)[0][0])\n",
    "    table.append(yhat)\n",
    "    start = np.array([table[-5:]])\n",
    "\n",
    "r = np.array(table, dtype=int)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 3, 7, 8, 9]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = [3,3,2,8,3,7,8,9]\n",
    "table[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "pas = 600000\n",
    "timeprevision = []\n",
    "timestamp = 1549979100000\n",
    "for i in range(19):\n",
    "    timeprevision.append(timestamp+i*pas)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1549979100000,\n",
       " 1549979700000,\n",
       " 1549980300000,\n",
       " 1549980900000,\n",
       " 1549981500000,\n",
       " 1549982100000,\n",
       " 1549982700000,\n",
       " 1549983300000,\n",
       " 1549983900000,\n",
       " 1549984500000,\n",
       " 1549985100000,\n",
       " 1549985700000,\n",
       " 1549986300000,\n",
       " 1549986900000,\n",
       " 1549987500000,\n",
       " 1549988100000,\n",
       " 1549988700000,\n",
       " 1549989300000,\n",
       " 1549989900000]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeprevision"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
